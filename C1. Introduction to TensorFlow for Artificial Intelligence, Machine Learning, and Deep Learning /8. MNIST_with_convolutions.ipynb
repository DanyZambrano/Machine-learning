{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8. MNIST with convolutions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Improve MNIST with Convolutions\n",
        "\n",
        "Para este ejercicio, vea si puede mejorar MNIST al 99,5 % de precisión o más agregando solo una capa convolucional y una capa MaxPooling 2D al modelo de la asignación de la semana anterior.\n",
        "\n",
        "Debe dejar de entrenar una vez que la precisión supere esta cantidad. Debería ocurrir en menos de 10 épocas, por lo que está bien codificar la cantidad de épocas para el entrenamiento, pero su entrenamiento debe terminar una vez que alcance la métrica anterior. Si no es así, deberá rediseñar su devolución de llamada.\n",
        "\n",
        "Cuando se haya alcanzado el 99,5 % de precisión, debe imprimir la cadena \"Se alcanzó el 99,5 % de precisión, por lo que se canceló el entrenamiento\"."
      ],
      "metadata": {
        "id": "KKdJbVj-_kJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Pf4mlGr_dXN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "mnist = tf.keras.datasets.mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "# Discard test set\n",
        "(training_images, training_labels), _ =  mnist.load_data()\n",
        "      \n"
      ],
      "metadata": {
        "id": "TwUsV0xpAQ4_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_and_normalize(images):\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape([60000, 28, 28, 1])\n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images / 255.0\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "TJcIWsaABRY4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un paso importante cuando se trata de datos de imágenes es preprocesar los datos. Durante el paso de preprocesamiento, puede aplicar transformaciones al conjunto de datos que se alimentará a su red neuronal convolucional.\n",
        "Aquí aplicará dos transformaciones a los datos:\n",
        "\n",
        "\n",
        "Remodele los datos para que tengan una dimensión adicional. La razón de esto es que normalmente utilizará matrices tridimensionales (sin contar la dimensión del lote) para representar datos de imagen. La tercera dimensión representa el color usando valores RGB. Estos datos pueden estar en formato blanco y negro, por lo que la tercera dimensión en realidad no agrega ninguna información adicional para el proceso de clasificación, pero es una buena práctica a pesar de todo.\n",
        "\n",
        "\n",
        "Normalice los valores de píxel para que sean valores entre 0 y 1. Puede lograr esto dividiendo cada valor en la matriz por el máximo.\n",
        "Recuerda que estos tensores son del tipo numpy.ndarray, por lo que puedes usar funciones como reformar o dividir para completar la siguiente función reformar_y_normalizar:"
      ],
      "metadata": {
        "id": "ud0HWnyeBv1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcbNrefEBvha",
        "outputId": "f1da382a-872c-4a87-b3b0-da745dcb98f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if logs.get('accuracy') > 0.995:\n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
        "                self.model.stop_training = True\n",
        "\n"
      ],
      "metadata": {
        "id": "2g8nO8B0L0fo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model, it should have 5 layers:\n",
        "    # - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function\n",
        "    #    and an input shape that matches that of every image in the training set\n",
        "    # - A MaxPooling2D layer with a pool_size of 2x2\n",
        "    # - A Flatten layer with no arguments\n",
        "    # - A Dense layer with 128 units and ReLU activation function\n",
        "    # - A Dense layer with 10 units and softmax activation function\n",
        "    model = tf.keras.models.Sequential([ \n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ]) \n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "oxb7yuD7L3-b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LphHZDwQL7Os",
        "outputId": "43175d5e-f5f4-4202-8b4e-208490a99bd6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1391 - accuracy: 0.9585\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0469 - accuracy: 0.9851\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0321 - accuracy: 0.9900\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0230 - accuracy: 0.9925\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0178 - accuracy: 0.9944\n",
            "Epoch 6/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9956\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0135 - accuracy: 0.9956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TZunnFhL9n7",
        "outputId": "f16a2dde-d9d5-4c08-a702-865cc40ff233"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your model was trained for 6 epochs\n"
          ]
        }
      ]
    }
  ]
}