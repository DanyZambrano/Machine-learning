{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ussing Callbacks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks\n",
        "\n",
        "Emplearemos callbacks para deterner el entrenamiento de nuestra red neuronal, cuando una metrica de nuestro training reuna los requerimientos.\n",
        "\n",
        "en escencia si tenemos 5000 epochs y ya la precicison y perdida estan bien a los 200 epochs no ncesitamos que el computador siga procesando.\n",
        "\n"
      ],
      "metadata": {
        "id": "4PqFat85aw7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importar y cargar la Data "
      ],
      "metadata": {
        "id": "yjBNqMk8bWac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovi5Ybq5aRDh",
        "outputId": "c7438ac2-2507-4572-8e0d-ec189d541ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# Cargamos la Data\n",
        "(x_train, y_train),(x_test, y_test) = fmnist.load_data()\n",
        "\n",
        "# Normalizamos la Data a nivel de pixeles\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creamos un callback\n",
        "\n",
        "Detendremos el entrenamiento cuando alcancemos un loss menor del 0.4.\n",
        "\n",
        "Args:\n",
        "\n",
        "- epoch: numero de ciclos\n",
        "- logs: resultado de la metrica basado en el epch training\n"
      ],
      "metadata": {
        "id": "-DHMAve4br7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # Chequeamos la precision\n",
        "    if(logs.get('loss') < 0.4):\n",
        "      # Detenemos el proceso\n",
        "      print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "kVnUfHbKbwAd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construimos y compilamos el Modelo"
      ],
      "metadata": {
        "id": "iNdAESOpcoVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el Modelo\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compilamos el Modelo\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ecD8BVQudGOi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamos el Modelo"
      ],
      "metadata": {
        "id": "gHXVnM82dVTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CuhNp-edUPV",
        "outputId": "cd5c19ad-f9bf-4a37-ee7e-23f88d444335"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 13s 6ms/step - loss: 0.4765 - accuracy: 0.8294\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8696\n",
            "Loss is lower than 0.4 so cancelling training!\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.3577 - accuracy: 0.8696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef63edb450>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}